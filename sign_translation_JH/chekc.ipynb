{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from hangul_utils import join_jamos\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import os\n",
    "font_path = './ttf_files/휴먼매직체.ttf'\n",
    "os.path.exists(font_path)\n",
    "\n",
    "font = ImageFont.truetype(font_path, 30)\n",
    "\n",
    "\n",
    "# Normalization\n",
    "def normalize_landmarks(landmarks):\n",
    "    landmarks_array = np.array([[landmark.x, landmark.y, landmark.z] for landmark in landmarks], dtype=np.float32)\n",
    "    norm_landmarks = landmarks_array - np.mean(landmarks_array, axis=0)\n",
    "    max_dist = np.max(np.linalg.norm(norm_landmarks, axis=1))\n",
    "    norm_landmarks = norm_landmarks / max_dist\n",
    "    return norm_landmarks\n",
    "\n",
    "# 왼손인지 오른손인지 할당\n",
    "def assign_hands_by_position(multi_hand_landmarks, image_width):\n",
    "    # Assuming that the wrist is the first landmark in the hand landmarks list\n",
    "    wrist_landmark_index = 0\n",
    "\n",
    "    hands_x_positions = [\n",
    "        hand.landmark[wrist_landmark_index].x for hand in multi_hand_landmarks\n",
    "    ]\n",
    "\n",
    "    left_hand_index = np.argmin(hands_x_positions)\n",
    "    right_hand_index = 1 - left_hand_index  # The other hand is the right hand\n",
    "\n",
    "\n",
    "    if hands_x_positions[left_hand_index] * image_width < hands_x_positions[right_hand_index] * image_width:\n",
    "        hand_landmarks_0 = multi_hand_landmarks[left_hand_index]\n",
    "        hand_landmarks_1 = multi_hand_landmarks[right_hand_index]\n",
    "    else:\n",
    "        hand_landmarks_0 = multi_hand_landmarks[right_hand_index]\n",
    "        hand_landmarks_1 = multi_hand_landmarks[left_hand_index]\n",
    "\n",
    "    return hand_landmarks_0, hand_landmarks_1\n",
    "\n",
    "# 현재 손가락과 엄지가 닿았는지 확인하기위한 함수 calculate_distance, check_fingers_touching\n",
    "def calculate_distance(landmark1, landmark2):\n",
    "    return np.sqrt((landmark1[0] - landmark2[0])**2 + (landmark1[1] - landmark2[1])**2 + (landmark1[2] - landmark2[2])**2)\n",
    "\n",
    "def check_fingers_touching(thumb_tip,index_finger_tip,middle_finger_tip,):\n",
    "    THUMB_INDEX_THRESHOLD = 0.22\n",
    "    THUMB_MIDDLE_THRESHOLD = 0.22\n",
    "\n",
    "    thumb_index_distance = calculate_distance(thumb_tip, index_finger_tip)\n",
    "    thumb_middle_distance = calculate_distance(thumb_tip, middle_finger_tip)\n",
    "\n",
    "    thumb_index_touching = thumb_index_distance < THUMB_INDEX_THRESHOLD\n",
    "    thumb_middle_touching = thumb_middle_distance < THUMB_MIDDLE_THRESHOLD\n",
    "\n",
    "    return thumb_index_touching, thumb_middle_touching\n",
    "\n",
    "\n",
    "# 왼손의 시그널 : 원그리기\n",
    "def draw_hand_circle(image, hand_landmarks, touching, color, thickness=2, radius=30,THUMB_TIP_IDX=4):\n",
    "\n",
    "    if touching:\n",
    "        thumb_tip = hand_landmarks.landmark[THUMB_TIP_IDX]\n",
    "        \n",
    "        # 이미지의 크기에 맞춰서 실제 픽셀 좌표로 변환\n",
    "        image_width, image_height = image.shape[1], image.shape[0]\n",
    "        thumb_tip_x = int(thumb_tip.x * image_width)\n",
    "        thumb_tip_y = int(thumb_tip.y * image_height)\n",
    "        \n",
    "        # 원을 그립니다.\n",
    "        cv2.circle(image, (thumb_tip_x, thumb_tip_y), radius, color, thickness)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "\n",
    "\n",
    "# 쌍자음 처리\n",
    "def make_double_consonant(consonant):\n",
    "    if consonant == 'ㄱ':\n",
    "        return 'ㄲ'\n",
    "    elif consonant == 'ㄷ':\n",
    "        return 'ㄸ'\n",
    "    elif consonant == 'ㅂ':\n",
    "        return 'ㅃ'\n",
    "    elif consonant == 'ㅅ':\n",
    "        return 'ㅆ'\n",
    "    elif consonant == 'ㅈ':\n",
    "        return 'ㅉ'\n",
    "    else:\n",
    "        return consonant\n",
    "\n",
    "# 모음 처리\n",
    "def vowel_compensation(recorded_letters):\n",
    "    \"\"\"\n",
    "    ㅗㅐ = ㅙ\n",
    "    ㅗㅏ = ㅘ\n",
    "    ㅜㅔ = ㅞ\n",
    "    ㅜㅓ = ㅝ\n",
    "    \"\"\"\n",
    "    if recorded_letters[-2:] == 'ㅗㅐ':\n",
    "        return recorded_letters[:-2] + 'ㅙ'\n",
    "    elif recorded_letters[-2:] == 'ㅗㅏ':\n",
    "        return recorded_letters[:-2] + 'ㅘ'\n",
    "    elif recorded_letters[-2:] == 'ㅜㅔ':\n",
    "        return recorded_letters[:-2] + 'ㅞ'\n",
    "    elif recorded_letters[-2:] == 'ㅜㅓ':\n",
    "        return recorded_letters[:-2] + 'ㅝ'\n",
    "    else:\n",
    "        return recorded_letters\n",
    "\n",
    "\n",
    "# 오른쪽 흰화면에 글자출력\n",
    "def draw_text(image, text, position, font=font, font_size=20, color=(0, 0, 0)):\n",
    "    # OpenCV 이미지를 PIL 이미지로 변환\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "\n",
    "    # PIL 이미지에 텍스트 쓰기\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "\n",
    "    # PIL 이미지를 OpenCV 이미지로 다시 변환\n",
    "    return cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 모델실행\n",
    "def landmarks(data):\n",
    "    return np.array([[landmark['x'], landmark['y'], landmark['z']] for landmark in data]).transpose()\n",
    "\n",
    "def inference_model(norm_landmarks, model):\n",
    "    hand_data = []\n",
    "    for norm_data in norm_landmarks:\n",
    "        tmp= {\n",
    "            \"x\": float(norm_data[0]),\n",
    "            \"y\": float(norm_data[1]),\n",
    "            \"z\": float(norm_data[2])\n",
    "        }\n",
    "        hand_data.append(tmp)\n",
    "    \n",
    "    data = torch.tensor(landmarks(hand_data),dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    output = model(data).squeeze(0).detach().cpu().numpy()\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

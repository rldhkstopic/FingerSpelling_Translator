{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def download_youtube_video(youtube_url, save_path=\".\"):\n",
    "    yt = YouTube(youtube_url)\n",
    "    ys = yt.streams.get_highest_resolution()\n",
    "    ys.download(save_path)\n",
    "    return ys.default_filename\n",
    "\n",
    "# 유튜브 URL로부터 영상 다운로드\n",
    "video_filename = download_youtube_video('https://www.youtube.com/watch?v=6-E6qrs99-k')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frame 0\n",
      "Saving frame 1\n",
      "Saving frame 2\n",
      "Saving frame 3\n",
      "Saving frame 4\n",
      "Saving frame 5\n",
      "Saving frame 6\n",
      "Saving frame 7\n",
      "Saving frame 8\n",
      "Saving frame 9\n",
      "Saving frame 10\n",
      "Saving frame 11\n",
      "Saving frame 12\n",
      "Saving frame 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def capture_frames(video_path, frame_interval, prefix, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    saved_images = [os.path.join(output_dir, f\"{prefix}_{i}.png\") for i in range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), frame_interval) if cap.read()[0]]\n",
    "    cap.release()\n",
    "    return saved_images\n",
    "\n",
    "def capture_specific_frames(video_path, frame_list, prefix, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    saved_images = []\n",
    "    for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_list:\n",
    "            img_path = os.path.join(output_dir, f\"{prefix}_{i}.png\")\n",
    "            cv2.imwrite(img_path, frame)\n",
    "            saved_images.append(img_path)\n",
    "\n",
    "    cap.release()\n",
    "    return saved_images\n",
    "\n",
    "def preprocess_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(f'pr_{video_path}', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        cv2.putText(frame, f\"Frame: {frame_count}\", (frame_width - 350, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "def save_frames(video_path, frame_indices):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count in frame_indices:\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        print(f\"Saving frame {i}\")\n",
    "        cv2.imwrite(f\"frame_{i}.png\", frame)\n",
    "\n",
    "conso_list = [80, 170, 275, 380, 470, 560, 650, 730, 820, 920, 1020, 1120, 1200, 1290]\n",
    "\n",
    "save_frames(\"consonant korean.mp4\", conso_list)\n",
    "# preprocess_video(\"consonant korean.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: []\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rldhkstopic\\FingerSpelling_Translator\\project.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m     plt\u001b[39m.\u001b[39mimshow(image)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m plot_csv_landmarks(\u001b[39m'\u001b[39;49m\u001b[39m./dataset/korean/vowels_processed/csv/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\rldhkstopic\\FingerSpelling_Translator\\project.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m num_plots \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msqrt(num_plots))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m cols \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mceil(num_plots \u001b[39m/\u001b[39;49m rows))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m plot_num \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rldhkstopic/FingerSpelling_Translator/project.ipynb#W1sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels:\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Mediapipe utilities\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "\n",
    "def normalize_landmarks(landmarks):\n",
    "    \"\"\"Normalize landmarks to range [0, 1].\"\"\"\n",
    "    normalized = np.array([[landmark.x, landmark.y, landmark.z] for landmark in landmarks.landmark])\n",
    "    normalized -= np.min(normalized, axis=0)\n",
    "    normalized /= np.max(normalized, axis=0)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def draw_bounding_box(frame, normalized_landmarks):\n",
    "    \"\"\"Draw bounding box around normalized hand landmarks.\"\"\"\n",
    "    x_min, y_min, _ = np.min(normalized_landmarks, axis=0)\n",
    "    x_max, y_max, _ = np.max(normalized_landmarks, axis=0)\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range\n",
    "    y_min -= y_range\n",
    "    x_max += x_range\n",
    "    y_max += y_range\n",
    "    x_min, y_min = max(0, x_min), max(0, y_min)\n",
    "    x_max, y_max = min(1, x_max), min(1, y_max)\n",
    "    cv2.rectangle(frame, \n",
    "                  (int(x_min * frame.shape[1]), int(y_min * frame.shape[0])), \n",
    "                  (int(x_max * frame.shape[1]), int(y_max * frame.shape[0])), \n",
    "                  (0, 255, 0), 2\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_3d_landmarks(normalized_landmarks):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x, y, z = zip(*normalized_landmarks)\n",
    "    \n",
    "    for connection in mp_hands.HAND_CONNECTIONS:\n",
    "        x_pair = [x[connection[0]], x[connection[1]]]\n",
    "        y_pair = [y[connection[0]], y[connection[1]]]\n",
    "        z_pair = [z[connection[0]], z[connection[1]]]\n",
    "        ax.plot(x_pair, y_pair, z_pair, color='b')\n",
    "\n",
    "    ax.scatter(x, y, z, s=10, c='r')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.view_init(elev=45., azim=-90.)  # Adjust camera angles for a better view\n",
    "    \n",
    "    plt.ion()  # Interactive mode ON\n",
    "    plt.show()\n",
    "\n",
    "import csv\n",
    "\n",
    "def process_images_in_directory(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image_rgb)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                print(f\"{results.multi_handedness} hands detected.\")\n",
    "                for i, landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image, landmarks, \n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                        mp_drawing_styles.get_default_hand_connections_style()\n",
    "                    )\n",
    "                    normalized_landmarks = normalize_landmarks(landmarks)\n",
    "\n",
    "                    csv_filename = os.path.splitext(filename)[0] + \".csv\"\n",
    "                    csv_path = os.path.join(output_dir, 'csv', csv_filename)\n",
    "                    with open(csv_path, mode='w', newline='') as csv_file:\n",
    "                        writer = csv.writer(csv_file)\n",
    "                        writer.writerow(['label', 'x', 'y', 'z'])\n",
    "                        for j, landmark in enumerate(normalized_landmarks):\n",
    "                            writer.writerow([f\"{os.path.splitext(filename)[0]}\", landmark[0], landmark[1], landmark[2]])\n",
    "\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "            \n",
    "def plot_csv_landmarks(csv_dir):\n",
    "    \"\"\"Plot hand landmarks from CSV files in directory with subplots for each label.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    labels = sorted(set([str(os.path.splitext(filename)[0]) for filename in os.listdir(csv_dir) if filename.endswith(\".csv\")]))\n",
    "    print(f\"Labels: {labels}\")\n",
    "    num_plots = len(labels)\n",
    "    rows = int(np.sqrt(num_plots))\n",
    "    cols = int(np.ceil(num_plots / rows))\n",
    "    plot_num = 1\n",
    "    for label in labels:\n",
    "        ax = fig.add_subplot(rows, cols, plot_num, projection='3d')\n",
    "        ax.set_title(label)\n",
    "        plot_num += 1\n",
    "\n",
    "        # Plot hand landmarks for label\n",
    "        for filename in os.listdir(csv_dir):\n",
    "            if filename.endswith(\".csv\") and os.path.splitext(filename)[0] == label:\n",
    "                csv_path = os.path.join(csv_dir, filename)\n",
    "                with open(csv_path, mode='r') as csv_file:\n",
    "                    reader = csv.reader(csv_file)\n",
    "                    next(reader)  # Skip header row\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    z = []\n",
    "                    for row in reader:\n",
    "                        x.append(float(row[1]))\n",
    "                        y.append(float(row[2]))\n",
    "                        z.append(float(row[3]))\n",
    "                    for connection in mp_hands.HAND_CONNECTIONS:\n",
    "                        x_pair = [x[connection[0]], x[connection[1]]]\n",
    "                        y_pair = [y[connection[0]], y[connection[1]]]\n",
    "                        z_pair = [z[connection[0]], z[connection[1]]]\n",
    "                        ax.plot(x_pair, y_pair, z_pair, color='b')\n",
    "                    ax.scatter(x, y, z, s=10, c='r')\n",
    "\n",
    "                    ax.set_xlabel('X')\n",
    "                    ax.set_ylabel('Y')\n",
    "                    ax.set_zlabel('Z')\n",
    "                    ax.view_init(elev=45., azim=-45.)  # Adjust camera angles for a better view\n",
    "     \n",
    "    # plt.title(\"Hand Landmarks\")   \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def process_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(image)\n",
    "    print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=hand_landmarks,\n",
    "                connections=mp_hands.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_hand_connections_style(),\n",
    "            )\n",
    "\n",
    "            normalize_landmarks(hand_landmarks)\n",
    "            draw_bounding_box(image, normalize_landmarks(hand_landmarks))\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "plot_csv_landmarks('./dataset/korean/vowels_processed/csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9954187\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9984596\n",
      "  label: \"Left\"\n",
      "}\n",
      ", classification {\n",
      "  index: 0\n",
      "  score: 0.9695541\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99731225\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99873877\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99734986\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9962988\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.98381436\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9970956\n",
      "  label: \"Left\"\n",
      "}\n",
      ", classification {\n",
      "  index: 0\n",
      "  score: 0.65354013\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9604102\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9914098\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9337775\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9975026\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99348855\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99012613\n",
      "  label: \"Left\"\n",
      "}\n",
      ", classification {\n",
      "  index: 0\n",
      "  score: 0.7879167\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.98058534\n",
      "  label: \"Left\"\n",
      "}\n",
      ", classification {\n",
      "  index: 0\n",
      "  score: 0.848215\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9954843\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99546033\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 1\n",
      "  score: 0.8296952\n",
      "  label: \"Right\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.96394724\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9939433\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.6668042\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.86261463\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.97172785\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9859701\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99291235\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.99965125\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.94289696\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9939724\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.98851675\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.9908412\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.7845162\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n",
      "[classification {\n",
      "  index: 0\n",
      "  score: 0.97753334\n",
      "  label: \"Left\"\n",
      "}\n",
      ", classification {\n",
      "  index: 0\n",
      "  score: 0.95374715\n",
      "  label: \"Left\"\n",
      "}\n",
      "] hands detected.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"23.png\"\n",
    "video_path = 'fingerspelling korean.mp4'\n",
    "\n",
    "set_path = './dataset/korean/samples/vowels/'\n",
    "# process_image(cv2.imread(os.path.join(set_path, image_path)))\n",
    "\n",
    "process_images_in_directory(set_path, './dataset/korean/vowels_processed/')\n",
    "# plot_csv_landmarks('./dataset/korean/vowels_processed/csv/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MediaDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
